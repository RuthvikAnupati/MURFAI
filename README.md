# MIKA â€“ AI-Powered Real-Time Voice Conversational Agent

![Python](https://img.shields.io/badge/Python-3.10-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-ğŸš€-green)
![MurfAI](https://img.shields.io/badge/Murf%20AI-TTS-orange)
![AssemblyAI](https://img.shields.io/badge/AssemblyAI-STT-yellow)
![GoogleGemini](https://img.shields.io/badge/Google-Gemini-lightblue)
![License](https://img.shields.io/badge/License-MIT-purple)

---
## ğŸ“Œ Overview
**MIKA** is a Voice-Enabled Conversational AI Web Application built with **FastAPI** as the backend and a modern web UI for real-time, two-way voice communication with an AI agent.

The application allows users to speak naturally to the AI, processes the voice input via integrated APIs, and responds back with real-time AI-generated speech. This creates an interactive experience similar to talking with a human voice assistant.

---
## ğŸš€ Features
- ğŸ¤ **Voice Input**: Speak directly to the AI agent through the browser.
- ğŸ§  **AI Understanding**: Processes voice queries and understands context.
- ğŸ”Š **Voice Output**: AI responds back in realistic, high-quality speech.
- âš¡ **FastAPI Backend**: High-performance, scalable API layer.
- ğŸŒ **Web-Based UI**: Minimal, responsive, and interactive interface for a smooth experience.

---

## ğŸ›  Technologies Used
- **Frontend**: HTML, CSS, JavaScript (Responsive UI)
- **Backend**: FastAPI (Python)
- **APIs**: Murf Api , Assemblu API , Google API

---

## ğŸ“‚ Project Structure
```
project-root/
â”‚â”€â”€ main.py                  # FastAPI entry point
â”‚â”€â”€ requirements.txt         # Python dependencies
â”‚â”€â”€ .env                     # Environment variables
â”‚â”€â”€ static/                  # Static assets (audio, video, icons, CSS, JS)
â”‚   â”œâ”€â”€ favicon.ico
â”‚   â”œâ”€â”€ error.wav
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ welcome.html
â”‚   â”œâ”€â”€ v1.mp4
â”‚   â”œâ”€â”€ v2.mp4
â”‚   â””â”€â”€ transcribe/          # Additional static resources
â”‚
â”‚â”€â”€ uploads/                 # Temporary audio uploads
â”‚â”€â”€ templates/               # Jinja2 HTML templates (if any)
â”‚â”€â”€ venv/                    # Virtual environment
â”‚â”€â”€ README.md                # Documentation
```

---

## ğŸ— System Architecture
1. **Frontend / API Client** sends text or file to the backend API.
2. **FastAPI server** processes the request.
3. **Murf AI API** generates the speech file.
4. The generated audio is stored locally or returned as a response.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¤ Frontend UI  â”‚â”€â”€â”€â”€â–¶â”‚ ğŸš€ FastAPI API  â”‚â”€â”€â”€â”€â–¶â”‚  ğŸ§  AI Services â”‚
â”‚                  â”‚      â”‚                  â”‚     â”‚                  â”‚
â”‚ â€¢ Audio Record   â”‚      â”‚ â€¢ Pipeline Mgmt  â”‚     â”‚ â€¢ AssemblyAI STT â”‚
â”‚ â€¢ Visualization  â”‚      â”‚ â€¢ Session Memory â”‚     â”‚ â€¢ Google Gemini  â”‚
â”‚ â€¢ Playback       â”‚      â”‚ â€¢ Error Handling â”‚     â”‚ â€¢ Murf AI TTS    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Pipeline Flow
1. **Audio Capture** â†’ Browser records user speech via MediaRecorder API.
2. **Speech Recognition (STT)** â†’ AssemblyAI transcribes audio to text.
3. **AI Processing (LLM)** â†’ Google Gemini (or other LLM) generates a response with personality.
4. **Voice Synthesis (TTS)** â†’ Murf AI converts response text to natural-sounding speech.
5. **Playback** â†’ Browser plays generated voice with real-time waveform visualizations.

---

## âš™ Environment Variables
Create a `.env` file in the project root with:
```
MURF_API_KEY=your_murf_api_key
ASSEMBLYAI_API_KEY=your_assemblyai_key
GOOGLE_API_KEY=your_google_api_key
```

---
## ğŸ“¦ Installation & Running
1. **Clone the repository**
```bash
git clone https://github.com/RuthvikAnupati/MURFAI.git
cd MURFAI
```

2. **Create a virtual environment & activate**
```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate    # Windows
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Run the API server**
```bash
uvicorn main:app --reload --port 4554
```
*(Change port number as needed)*

---

## ğŸ”— API Endpoints
| Method | Endpoint         | Description                |
|--------|-----------------|----------------------------|
| POST   | `/upload`        | Upload text/file for TTS    |
| GET    | `/audio/{id}`    | Retrieve generated audio    |
| GET    | `/`              | Home / API status           |

---

## ğŸ“¸ Screenshots
Home Page <img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/363a9e76-ef25-47bf-a461-31cfd829e56b" />
Main Page <img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/c695f390-cc9b-4f33-a3cd-adcc6127e9a6" />


---

## ğŸ“œ License
This project is licensed under the MIT License.
