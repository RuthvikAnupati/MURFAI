# MIKA â€“ AI-Powered Voice Agent!

## ğŸ“Œ Overview
MIKA is an AI-powered application built with **FastAPI** and integrated with **Murf AI API** for generating high-quality speech from text.  
The project provides REST APIs to upload text or files and receive generated speech in multiple formats.

---

## âœ¨ Key Features
- ğŸ™ **Real-time Voice Conversations** â€“ Talk naturally with MIKA, no typing required.
- ğŸ­ **Unique Personality** â€“ Configurable conversational style for engaging AI interactions.
- ğŸ“± **Modern UI/UX** â€“ Glassmorphic design with smooth animations and audio visualizations.
- ğŸ”„ **Session Persistence** â€“ Maintains context for multi-turn conversations.
- âš¡ **Low Latency Pipeline** â€“ Optimized for near real-time responses.
- ğŸ›¡ **Robust Error Handling** â€“ Graceful degradation on STT/LLM/TTS failures.
- ğŸµ **Audio Visualizations** â€“ Real-time waveform feedback during recording and playback.

---

## ğŸ›  Technologies Used
- **Python 3.9+**
- **FastAPI** â€“ Backend API
- **httpx** â€“ Asynchronous HTTP client
- **dotenv** â€“ Environment configuration
- **Pydantic** â€“ Request/response validation
- **AssemblyAI API** â€“ Speech-to-text
- **Google Generative AI API** â€“ Language model processing (optional)
- **Murf AI API** â€“ Text-to-speech synthesis
- **HTML5, CSS3, Vanilla JS** â€“ Frontend

---

## ğŸ“‚ Project Structure
```plaintext
project-root/
â”‚â”€â”€ main.py                  # FastAPI entry point
â”‚â”€â”€ requirements.txt         # Python dependencies
â”‚â”€â”€ .env                     # Environment variables
â”‚â”€â”€ static/                  # Static assets (audio, video, icons, CSS, JS)
â”‚   â”œâ”€â”€ favicon.ico
â”‚   â”œâ”€â”€ error.wav
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ welcome.html
â”‚   â”œâ”€â”€ v1.mp4
â”‚   â”œâ”€â”€ v2.mp4
â”‚   â””â”€â”€ transcribe/          # Additional static resources
â”‚
â”‚â”€â”€ uploads/                 # Temporary audio uploads
â”‚â”€â”€ templates/               # Jinja2 HTML templates (if any)
â”‚â”€â”€ venv/                    # Virtual environment
â”‚â”€â”€ README.md                # Documentation
---

## ğŸ— System Architecture
1. **Frontend / API Client** sends text or file to the backend API.
2. **FastAPI server** processes the request.
3. **Murf AI API** generates the speech file.
4. The generated audio is stored locally or returned as a response.
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¤ Frontend UI  â”‚â”€â”€â”€â”€â–¶â”‚ ğŸš€ FastAPI API  â”‚â”€â”€â”€â”€â–¶â”‚  ğŸ§  AI Services â”‚
â”‚                  â”‚      â”‚                  â”‚     â”‚                  â”‚
â”‚ â€¢ Audio Record   â”‚      â”‚ â€¢ Pipeline Mgmt  â”‚     â”‚ â€¢ AssemblyAI STT â”‚
â”‚ â€¢ Visualization  â”‚      â”‚ â€¢ Session Memory â”‚     â”‚ â€¢ Google Gemini  â”‚
â”‚ â€¢ Playback       â”‚      â”‚ â€¢ Error Handling â”‚     â”‚ â€¢ Murf AI TTS    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


---
ğŸ”„ Pipeline Flow
1. Audio Capture â†’ Browser records user speech via MediaRecorder API.
2. Speech Recognition (STT) â†’ AssemblyAI transcribes audio to text.
3. AI Processing (LLM) â†’ Google Gemini (or other LLM) generates a response with personality.
4. Voice Synthesis (TTS) â†’ Murf AI converts response text to natural-sounding speech.
5. Playback â†’ Browser plays generated voice with real-time waveform visualizations.
---

## âš™ Environment Variables
Create a `.env` file in the project root with:
```
ASSEMBLYAI_API_KEY=your_assemblyai_api_key
GOOGLE_API_KEY=your_google_api_key
MURF_API_KEY=your_murf_api_key

```
*(Only include GOOGLE_API_KEY if using Google Generative AI)*

---

## ğŸ“¦ Installation & Running
1. **Clone the repository**
```bash
git clone https://github.com/RuthvikAnupati/MURFAI.git
cd MURFAI
```

2. **Create a virtual environment & activate**
```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate    # Windows
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Run the API server**
```bash
uvicorn main:app --reload --port 4554
```
*(Change port number as needed)*

---

## ğŸ”— API Endpoints
| Method | Endpoint         | Description                |
|--------|------------------|----------------------------|
| POST   | `/upload`        | Upload text/file for TTS   |
| GET    | `/audio/{id}`    | Retrieve generated audio   |
| GET    | `/`              | Home / API status          |

---

## ğŸ“¸ Screenshots
<img width="1920" height="873" alt="12 1" src="https://github.com/user-attachments/assets/1331d800-cd43-464c-a9b5-e1f0245a7ddd" />
<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/ca5e648a-f66f-49f0-88f4-fddb5c522135" />

---

## ğŸ“œ License
This project is licensed under the MIT License.
